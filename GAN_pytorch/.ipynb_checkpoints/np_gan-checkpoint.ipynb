{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f554364-9415-4ef4-b28e-33e152f8af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6291025-ab55-4899-8327-f87815cf85ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_DIM = 1\n",
    "G_HIDDEN = 10\n",
    "X_DIM = 10\n",
    "D_HIDDEN = 10\n",
    "\n",
    "step_size_G = 0.01\n",
    "step_size_D = 0.01\n",
    "ITER_HUM = 50000\n",
    "\n",
    "GRADIENT_CLIP = 0.2\n",
    "WEIGHT_CLIP = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31916cfd-0056-4e05-aa0d-365c37b7047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(random=True):\n",
    "    if random:\n",
    "        x0 = np.random.uniform(0, 1)\n",
    "        freq = np.random.uniform(1.2, 1.5)\n",
    "        mult = np.random.uniform(0.5, 0.8)\n",
    "        \n",
    "    else:\n",
    "        x0 = 0\n",
    "        freq = 0.2\n",
    "        mult = 1\n",
    "        \n",
    "    signal = [mult * np.sin(x0+freq*i) for i in range(X_DIM)]\n",
    "    \n",
    "    return np.array*(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f6ce5d-2f75-4965-8fcb-089dc963966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.maximum(x, 0.)\n",
    "\n",
    "def dReLU(x):\n",
    "    return ReLU(x)\n",
    "\n",
    "def LeakyReLU(x, k=0.2):\n",
    "    return np.where(x >= 0, x, x * k)\n",
    "\n",
    "def Tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dTanh(x):\n",
    "    return 1. - Tanh(x)**x\n",
    "\n",
    "def Sigmoid(x):\n",
    "    return 1./ (1.+np.exp(-x))\n",
    "\n",
    "def dSigmoid(x):\n",
    "    return Sigmoid(x) * ( 1. - Sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e18603d-6e38-4904-b62d-60a486c67e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_initializer(in_channels, out_channels):\n",
    "    scale = np.sqrt(2./(in_channels+out_channels))\n",
    "    return np.random.uniform(-scale, scale, (in_channels, out_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87a03ca-55b5-4f3f-ba53-744501c8353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunc(object):\n",
    "    def __init__(self):\n",
    "        self.logit = None\n",
    "        self.label = None\n",
    "        \n",
    "    def forward(self, logit, label):\n",
    "        if logit[0, 0] < 1e-7:\n",
    "            logit[0, 0] = 1e-7\n",
    "        if 1.-logit[0, 0] < 1e-7:\n",
    "            logit[0,0] = 1. - 1e-7\n",
    "        self.logit = logit\n",
    "        self.label = label\n",
    "        return -(label*np.log(logit) + (1-label)*np.log(1-logti))\n",
    "    \n",
    "    def backward(self):\n",
    "        return (1-self.label)/(1-self.logit) - self.label/self.logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd37f6-f9e5-4541-a1b2-76ce86791888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    def __init__(self):\n",
    "        self.z = None\n",
    "        self.w1 = weight_initializer(Z_DIM, G_HIDDEN)\n",
    "        self.b1 = weight_initializer(1, G_HIDDEN)\n",
    "        self.x1 = None\n",
    "        self.w2 = weight_initializer(G_HIDDEN, G_HIDDEN)\n",
    "        self.b2 = weight_initializer(1, G_HIDDEN)\n",
    "        self.x2 = None\n",
    "        self.w3 = weight_initializer(G_HIDDEN, X_DIM)\n",
    "        self.b3 = weight_initializer(1, X_DIM)\n",
    "        self.x3 = None\n",
    "        self.x = None\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.z = inputs.reshape(1, Z_DIM)\n",
    "        self.x1 = np.matmul(self.z, self.w1) + self.b1\n",
    "        self.x1 = ReLU(self.x1)\n",
    "        self.x2 = np.matmul(self.x1, self.w2) + self.b2\n",
    "        self.x2 = ReLU(self.x2)\n",
    "        self.x3 = np.matmul(self.x2, self.w3) + self.b3\n",
    "        self.x = Tanh(self.x3)\n",
    "        return self.x\n",
    "    \n",
    "    def backward(self, outputs):\n",
    "        # Derivative with respect to output\n",
    "        delta = outputs\n",
    "        delta *= dTanh(self.x)\n",
    "        # Derivative with respect to w3\n",
    "        d_w3 = np.matmul(np.transpose(self.x2), delta)\n",
    "        # Derivative with respect to b3\n",
    "        d_b3 = delta.copy()\n",
    "        \n",
    "        # Derivative with respect to x2\n",
    "        delta = np.matmul(delta, np.transpose(self.w3))\n",
    "        \n",
    "        # Update w3\n",
    "        if (np.linalg.norm(d_w3) > GRADIENT_CLIP):\n",
    "            d_w3 = GRADIENT_CLIP / np.linalg.norm(d_w3) * d_w3\n",
    "        self.w3 -= step_size_G * d_w3\n",
    "        self.w3 = np.maximum(-WEIGHT_CLIP, np.minimum(WEIGHT_CLIP, self.w3))\n",
    "        \n",
    "        # Update b3\n",
    "        self.b3 -= step_size_G * d_b3\n",
    "        self.b3 = np.maximum(-WEIGHT_CLIP, np.minimum(WEIGHT_CLIP, self.b3))\n",
    "        delta *= dReLU(self.x2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
