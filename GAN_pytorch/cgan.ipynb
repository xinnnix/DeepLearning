{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b8c7758-fd68-48cc-8eac-f9687d5111df",
   "metadata": {},
   "source": [
    "cgan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f455f83b-faad-4497-9f3f-d24736898e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaef4b10-06db-401d-8465-7c63ad740e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, classes, channels, img_size, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.channels = channels\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
    "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *self._create_layer(self.latent_dim + self.classes, 128, False),\n",
    "            *self._create_layer(128, 256),\n",
    "            *self._create_layer(256, 512),\n",
    "            *self._create_layer(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(self.img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def _create_layer(self, size_in, size_out, normalize=True):\n",
    "        layers = [nn.Linear(size_in, size_out)]\n",
    "        if normalize:\n",
    "            layers.append(nn.BatchNorm1d(size_out))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        return layers\n",
    "    \n",
    "    def forward(self, noise, labels):\n",
    "        z = torch.cat((self.label_embedding(labels), noise), -1)\n",
    "        x = self.model(z)\n",
    "        x = x.view(x.size(0), *self.img_shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5a7be8-4352-4d75-b9d2-e965dd5ee86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, classes, channels, img_size, latent_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.channels = channels\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
    "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
    "        self.adv_loss = torch.nn.BCELoss()\n",
    "        self.model = nn.Sequential(\n",
    "            *self._create_layer(self.classes + int(np.prod(self.img_shape)), 1024, False, True),\n",
    "            *self._create_layer(1024, 512, True, True),\n",
    "            *self._create_layer(512, 256, True, True),\n",
    "            *self._create_layer(256, 128, False, False),\n",
    "            *self._create_layer(128, 1, False, False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def _create_layer(self, size_in, size_out, drop_out=True, act_func=True):\n",
    "        layers = [nn.Linear(size_in, size_out)]\n",
    "        if drop_out:\n",
    "            layers.append(nn.Dropout(0.4))\n",
    "        if act_func:\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        return layers\n",
    "    \n",
    "    def forward(self, image, labels):\n",
    "        x = torch.cat((image.view(image.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        return self.model(x)\n",
    "    \n",
    "    def loss(self, output, label):\n",
    "        return self.adv_loss(output, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a81d27-3d70-4ff3-b3d5-9bd88220a9b8",
   "metadata": {},
   "source": [
    "build_gan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93beede7-51a7-4236-84e8-4bc227ce3679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# from cgan import Generator as cganG\n",
    "# from cgan import Discriminator as cganD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24973a5a-42c4-4201-8f26-7bfa1d883531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, \n",
    "                 name, \n",
    "                 device,\n",
    "                 data_loader,\n",
    "                 classes,\n",
    "                 channels,\n",
    "                 img_size,\n",
    "                 latent_dim):\n",
    "        self.name = name\n",
    "        self.device = device\n",
    "        self.data_loader = data_loader\n",
    "        self.classes = classes\n",
    "        self.channels = channels\n",
    "        self.latent_dim = latent_dim\n",
    "        if self.name == 'cgan':\n",
    "            self.netG = cganG(self.classes, self.channels, self.img_size, self.latent_dim)\n",
    "        self.netG.to(self.device)\n",
    "        if self.name == 'cgan':\n",
    "            self.netD = cganD(self.classes, self.channels, self.img_size, self.latent_dim)\n",
    "        self.netD.to(device)\n",
    "        self.optim_G = None\n",
    "        self.optim_D = None\n",
    "        \n",
    "        \n",
    "    def create_optim(self, lr, alpha=0.5, beta=0.999):\n",
    "        self.optim_G = torch.optim.Adam(filter(lambda p: p.requires_grad, self.netG.parameters()), lr=lr, betas=(alpha, beta))\n",
    "        self.optim_D = torch.optim.Adam(filter(lambda p: p.requires_grad, self.netD.parameters()), lr=lr, betas=(alpha, beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c916ed8-f8f0-4526-bc58-3a08617e2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self,\n",
    "          epochs, \n",
    "          log_interval=100,\n",
    "          out_dir = '',\n",
    "          verbose=True):\n",
    "    self.netG.train()\n",
    "    self.netD.train()\n",
    "    viz_noise = torch.randn(self.data_loader.batch_size, self.latent_dim, device=self.device)\n",
    "    viz_label = torch.LongTensor(np.array([num for _ in range(nrows)\n",
    "                                           for num in range(8)])).to(self.device)\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(self.data_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            batch_size = data.size(0)\n",
    "            real_label = torch.full((batch_size, 1), 1., device=self.device)\n",
    "            fake_label = torch.full((batch_size, 1), 0., device=self.device)\n",
    "            \n",
    "            # Train G\n",
    "            self.netG.zero_grad()\n",
    "            z_noise = torch.randn(batch_size, self.latent_dim, device=self.device)\n",
    "            x_fake_labels = torch.randint(0, self.classes, (batch_size,), device=self.device)\n",
    "            x_fake = self.netG(z_noise, x_fake_labels)\n",
    "            y_fake_g = self.netD(x_fake, x_fake_labels)\n",
    "            g_loss = self.netD.loss(y_fake_g, real_label)\n",
    "            g_loss.backward()\n",
    "            self.optim_G.step()\n",
    "            \n",
    "            # Train D\n",
    "            self.netD.zero_grad()\n",
    "            y_real = self.netD(data, target)\n",
    "            d_real_loss = self.netD.loss(y_real, real_label)\n",
    "            \n",
    "            y_fake_d = self.netD(x_fake.detach(), x_fake_labels)\n",
    "            d_fake_loss = self.netD.loss(y_fake_d, fake_label)\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            self.optim_D.step()\n",
    "            \n",
    "            if verbose and batch_idx%log_interval==0 and batch_idx>0:\n",
    "                print('Epoch {} [{}/{}] loss_D: {:.4f} loss_G: {:.4f}'.format(epoch, batch_idx, len(self.data_loader),\n",
    "                                                                              d_loss.mean().item(), g_loss.mean().item()))\n",
    "                vutils.save_image(data, os.path.join(out_dir, 'real_samples.png'), normalize=True)\n",
    "                with torch.no_grad():\n",
    "                    viz_sample = self.netG(viz_noise, viz_label)\n",
    "                    vutils.save_image(viz_sample, os.path.join(out_dir, 'fake_samples_{}.png'.format(epoch)), nrow=8, normalize=True)\n",
    "        self.save_to(path=out_dir, name=self.name, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ccc8b-164d-44ac-a3a8-2dc58384133a",
   "metadata": {},
   "source": [
    "main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e1aa1e0-fb39-4366-9134-05ce2bb5afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import utils\n",
    "\n",
    "# from build_gan import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e6d0be1-3a56-4553-b32b-a99896f27bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = None\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda:0' if FLAGS.cuda else 'cpu')\n",
    "    \n",
    "    if FLAGS.train:\n",
    "        print('Loading data...\\n')\n",
    "        dataset = dset.MNIST(root=FLAGS.data_dir, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.Resize(FLAGS.img_size),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5,), (0.5,))]))\n",
    "        assert dataset\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=FLAGS.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        print('Creating model...\\n')\n",
    "        model = Model(FLAGS.model, device, dataloader, FLAGS.classes, FLAGS.channels, FLAGS.img_size, FLAGS.latent_dim)\n",
    "        model.create_optim(FLAGS.lr)\n",
    "        \n",
    "        # Train\n",
    "        model.train(FLAGS.epochs, FLAGS.log_interval, FLAGS.out_dir, True)\n",
    "        \n",
    "        model.save_to('')\n",
    "    else:\n",
    "        model = Model(FLAGS.model, device, None, FLAGS.classes, FLAGS.channels, FLAGS.img_size, FLAGS.latent_dim)\n",
    "        model.load_from(FLAGS.out_dir)\n",
    "        model.eval(mode=0, batch_size=FLAGS.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c91f76-56ed-49cd-814f-b4692c07eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    from utils import boolean_string\n",
    "    parser = argparse.ArgumentParser(description='Hands-On GANs - Chapter 5')\n",
    "    parser.add_argument('--model', type=str, default='cgan', help='one of `cgan` and `infogan`.')\n",
    "    parser.add_argument('--cuda', type=boolean_string, default=True, help='enable CUDA.')\n",
    "    parser.add_argument('--train', type=boolean_string, default=True, help='train mode or eval mode.')\n",
    "    parser.add_argument('--data_dir', type=str, default='~/Data/mnist', help='Directory for dataset.')\n",
    "    parser.add_argument('--out_dir', type=str, default='output', help='Directory for output.')\n",
    "    parser.add_argument('--epochs', type=int, default=200, help='number of epochs')\n",
    "    parser.add_argument('--batch_size', type=int, default=128, help='size of batches')\n",
    "    parser.add_argument('--lr', type=float, default=0.0002, help='learning rate')\n",
    "    parser.add_argument('--latent_dim', type=int, default=100, help='latent space dimension')\n",
    "    parser.add_argument('--classes', type=int, default=10, help='number of classes')\n",
    "    parser.add_argument('--img_size', type=int, default=64, help='size of images')\n",
    "    parser.add_argument('--channels', type=int, default=1, help='number of image channels')\n",
    "    parser.add_argument('--log_interval', type=int, default=100, help='interval between logging and image sampling')\n",
    "    parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
    "    \n",
    "    FLAGS = parser.parse_args()\n",
    "    \n",
    "    FLAGS.cuda = FLAGS.cuda and torch.cuda.is_available()\n",
    "    \n",
    "    if FLAGS.seed is not None:\n",
    "        torch.manual_seed(FLAGS.seed)\n",
    "        if FLAGS.cuda:\n",
    "            torch.cuda.manual_seed(FLAGS.seed)\n",
    "        np.random.seed(FLAGS.seed)\n",
    "        \n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    if FLAGS.train:\n",
    "        utils.clear_folder(FLAGS.out_dir)\n",
    "        \n",
    "    log_file = os.path.join(FLAGS.out_dir, 'log.txt')\n",
    "    print('Logging to {}\\n'.format(log_file))\n",
    "    sys.stdout = utils.StdOut(log_file)\n",
    "    print('PyTorch version: {}'.format(torch.__version__))\n",
    "    print('CUDA version: {}\\n'.format(torch.version.cuda))\n",
    "    \n",
    "    print(' ' * 9 + 'Args' + ' '*9 + '| ' + 'Type' +' | ' + 'Value')\n",
    "    print('-' * 50)\n",
    "    for arg in vars(FLAGS):\n",
    "        arg_str = str(arg)\n",
    "        var_str = str(getattr(FLAGS, arg))\n",
    "        type_str = str(type(getattr(FLAGS, arg)).__name__)\n",
    "        print(' ' + arg_str + ' ' * (20 - len(arg_str)) + '|' + \n",
    "              ' ' + type_str+ ' '*(10 - len(type_str)) + '|' + \n",
    "              ' ' _ var_str)\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fb0d1a-948e-44c2-a505-f13c2da1397a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
