{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e59407-07a8-471f-9421-99f661ef924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aa8c8f7-0eed-4c72-bcc8-4848840fb9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = True\n",
    "DATA_PATH = 'c:/Users/admin/Desktop/Dunhuang_dataset/'\n",
    "OUT_PATH = 'output_dunhuang_batchsize1024'\n",
    "LOG_FILE = os.path.join(OUT_PATH, 'log.txt')\n",
    "BATCH_SIZE = 100\n",
    "IMAGE_CHANNEL = 3\n",
    "Z_DIM = 100\n",
    "G_HIDDEN = 64\n",
    "X_DIM = 64\n",
    "D_HIDDEN = 64\n",
    "EPOCH_NUM = 500\n",
    "REAL_LABEL = 1.\n",
    "FAKE_LABEL = 0.\n",
    "lr = 2e-4\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b36708c-a7ca-4431-8546-a193c6ebb0ba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Logging to {}\\n'.format(LOG_FILE))\n",
    "sys.stdout = utils.StdOut(LOG_FILE)\n",
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "print('PyTorch version: {}'.format(torch.__version__))\n",
    "if CUDA:\n",
    "    print('CUDA version: {}\\n'.format(torch.version.cuda))\n",
    "if seed is None:\n",
    "    seed = np.random.randint(1, 10000)\n",
    "print('Random Seed: ', seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "cudnn.benchmark = True\n",
    "device = torch.device('cuda:0' if CUDA else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47735c35-59f2-4684-b4fe-0fa109946e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # 1st layer\n",
    "            nn.ConvTranspose2d(Z_DIM, G_HIDDEN*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN*8),\n",
    "            nn.ReLU(True),\n",
    "            # 2nd layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN*8, G_HIDDEN*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN*4),\n",
    "            nn.ReLU(True),\n",
    "            # 3rd layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN*4, G_HIDDEN*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN*2),\n",
    "            nn.ReLU(True),\n",
    "            # 4th layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN*2, G_HIDDEN, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(G_HIDDEN),\n",
    "            nn.ReLU(True),\n",
    "            # output layer\n",
    "            nn.ConvTranspose2d(G_HIDDEN, IMAGE_CHANNEL, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a3b4c7-5ebf-432f-a467-09717fce7806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = Generator()\n",
    "netG.load_state_dict(torch.load(os.path.join(OUT_PATH, 'netG_240.pth')))\n",
    "netG.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81c7d58d-8e53-451a-92bd-0076a1084f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "VIZ_MODE = 2\n",
    "\n",
    "\n",
    "if VIZ_MODE == 0:\n",
    "    viz_tensor = torch.randn(BATCH_SIZE, Z_DIM, 1, 1, device=device)\n",
    "elif VIZ_MODE == 1:\n",
    "    load_vector = np.loadtxt('vec_20230226-004944.txt')\n",
    "    xp = [0, 1]\n",
    "    yp = np.vstack([load_vector[2], load_vector[9]])\n",
    "    xvals = np.linspace(0, 1, num=BATCH_SIZE)\n",
    "    sample = interp1d(xp, yp, axis=0)\n",
    "    viz_tensor = torch.tensor(sample(xvals).reshape(BATCH_SIZE, Z_DIM, 1, 1), dtype=torch.float32, device=device)\n",
    "elif VIZ_MODE == 2:\n",
    "    load_vector = np.loadtxt('vec_20230226-004944.txt')\n",
    "    z1 = (load_vector[0] + load_vector[6] + load_vector[8])/3.\n",
    "    z2 = (load_vector[1] + load_vector[2] + load_vector[4])/3.\n",
    "    z3 = (load_vector[3] + load_vector[4] + load_vector[6])/3.\n",
    "    z_new = z1 - z2 + z3\n",
    "    sample = np.zeros(shape=(BATCH_SIZE, Z_DIM))\n",
    "    for i in range(BATCH_SIZE):\n",
    "        sample[i] = z_new + 0.1 * np.random.normal(-1.0, 1.0, 100)\n",
    "    viz_tensor = torch.tensor(sample.reshape(BATCH_SIZE, Z_DIM, 1, 1), dtype=torch.float32, device=device)\n",
    "\n",
    "    \n",
    "with torch.no_grad():\n",
    "    viz_sample = netG(viz_tensor)\n",
    "    viz_vector = utils.to_np(viz_tensor).reshape(BATCH_SIZE, Z_DIM)\n",
    "    cur_time = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    np.savetxt('vec_{}.txt'.format(cur_time), viz_vector)\n",
    "    vutils.save_image(viz_sample, 'img_{}.png'.format(cur_time), nrow=10, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c77e79-93d9-41db-97a1-19072f43184e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
