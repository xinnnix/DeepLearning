{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f13a88c-27cb-4e6e-8d84-15a559870325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import random\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b55f70b-6d58-4938-a185-28418d84867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'c:/Users/admin/Documents/Datasets/celeba_hq/'\n",
    "BUFFER_SIZE = 200\n",
    "IMAGE_RESOLUTION = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00202839-6f5b-4b13-9daf-da94b7daf132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(res, image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.image.resize(image, [res, res],\n",
    "                            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image/127.5)-1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a925e720-a371-4735-ad7b-3dc3eba9dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = {}\n",
    "train_images = glob(PATH + 'train/**/*.jpg')\n",
    "random.shuffle(train_images)\n",
    "train_dataset_list = tf.data.Dataset.from_tensor_slices(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b602396-7b78-4fbc-9e21-e7515d1cfc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_workers = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d88dc13e-ae35-4af1-82a5-d992d8a100db",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = {2: 16, 3: 16, 4: 16, 5: 16, 6: 16, 7: 8, 8: 4, 9: 4, 10: 4}\n",
    "TRAIN_STEP_RATIO = {k: BATCH_SIZE[2]/v for k, v in BATCH_SIZE.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03c9db42-cbff-4265-bbea-3075194166f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 2.0, 8: 4.0, 9: 4.0, 10: 4.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_STEP_RATIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5294a819-63be-48d3-9510-fc492fbb57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for log2_res in range(2, int(np.log2(IMAGE_RESOLUTION)) + 1):\n",
    "    res = 2**log2_res\n",
    "    temp = train_dataset_list.map(partial(load, res), num_parallel_calls=n_workers)\n",
    "    \n",
    "    temp = temp.shuffle(BUFFER_SIZE).batch(BATCH_SIZE[log2_res], drop_remainder=True).repeat()\n",
    "    train_datasets[log2_res] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "678b3e97-7cd7-4310-8ea9-0931d23057c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: <RepeatDataset element_spec=TensorSpec(shape=(16, 4, 4, None), dtype=tf.float32, name=None)>,\n",
       " 3: <RepeatDataset element_spec=TensorSpec(shape=(16, 8, 8, None), dtype=tf.float32, name=None)>,\n",
       " 4: <RepeatDataset element_spec=TensorSpec(shape=(16, 16, 16, None), dtype=tf.float32, name=None)>,\n",
       " 5: <RepeatDataset element_spec=TensorSpec(shape=(16, 32, 32, None), dtype=tf.float32, name=None)>,\n",
       " 6: <RepeatDataset element_spec=TensorSpec(shape=(16, 64, 64, None), dtype=tf.float32, name=None)>,\n",
       " 7: <RepeatDataset element_spec=TensorSpec(shape=(8, 128, 128, None), dtype=tf.float32, name=None)>,\n",
       " 8: <RepeatDataset element_spec=TensorSpec(shape=(4, 256, 256, None), dtype=tf.float32, name=None)>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4434dbfd-630f-4c83-aeb6-6d59b9349a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, log2_res, fname=''):\n",
    "    scales = {2:0.5, \n",
    "              3:1, \n",
    "              4:2, \n",
    "              5:3,\n",
    "              6:4,\n",
    "              7:5,\n",
    "              8:6, \n",
    "              9:7,\n",
    "              10:8}\n",
    "    scale = scales[log2_res]\n",
    "    \n",
    "    grid_col = min(12, int(12//scale))\n",
    "    grid_row = images.shape[0]//grid_col\n",
    "    grid_row = min(2, grid_row)\n",
    "    \n",
    "    f, axarr = plt.subplots(grid_row, grid_col, figsize=(grid_col*scale, grid_row*scale))\n",
    "    \n",
    "    for row in range(grid_row):\n",
    "        ax = axarr if grid_row==1 else axarr[row]\n",
    "        for col in range(grid_col):\n",
    "            ax[col].imshow(images[row*grid_col+col])\n",
    "            ax[col].axis('off')\n",
    "    plt.show()\n",
    "    if fname:\n",
    "        print('image name', fname)\n",
    "        f.savefig(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7ced1fb-bdbb-494d-8767-f04cde6431ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNorm(Layer):\n",
    "    def __init__(self, epsilon=1e-8):\n",
    "        super(PixelNorm, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        return input_tensor / tf.math.sqrt(tf.reduce_mean(input_tensor**2, axis=-1, keepdims=True) + self.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d64f33b-9ef3-432e-8dfc-df13cf2a6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinibatchStd(Layer):\n",
    "    def __init__(self, group_size=4, epsilon=1e-8):\n",
    "        super(MinibatchStd, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.group_size = group_size\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        n, h, w, c = input_tensor.shape\n",
    "        x = tf.reshape(input_tensor, [self.group_size, -1, h, w, c])\n",
    "        group_mean, group_var = tf.nn.moments(x, axes=(0), keepdims=False)\n",
    "        group_std = tf.sqrt(group_var + self.epsilon)\n",
    "        avg_std = tf.reduce_mean(group_std, axis=[1,2,3], keepdims=True)\n",
    "        x = tf.tile(avg_std, [self.group_size, h, w, 1])\n",
    "        \n",
    "        return tf.concat([input_tensor, x], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a872475-db05-44d0-a55d-538844d19b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FadeIn(Layer):\n",
    "    @tf.function\n",
    "    def call(self, input_alpha, a, b):\n",
    "        alpha = tf.reduce_mean(input_alpha)\n",
    "        y = alpha * a + ( 1. - alpha) * b\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ffa4d2f-6011-4b9b-8093-658739850490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return -tf.reduce_mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c8327-b13d-4915-8a85-14113473b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(Layer):\n",
    "    def __init__(self, out_channels, kernel=3, gain=2, **kwargs):\n",
    "        super(Conv2D, self).__init__(kwargs)\n",
    "        self.kernel = kernel\n",
    "        self.out_channels = out_channels\n",
    "        self.gain = gain\n",
    "        self.pad = kernel!=1\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.in_channels = input_shape[-1]\n",
    "        initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    "        self.w = self.add_weight(shape=[self.kernel,\n",
    "                                        self.kernel,\n",
    "                                        self.in_channels,\n",
    "                                        self.out_channels],\n",
    "                                 initializer=initializer,\n",
    "                                 trainable=True, name='kernel')\n",
    "        self.b = self.add_weight(shape=(self.out_channels,),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True, name='bias')\n",
    "        fan_in = self.kernel*self.kernel*self.in_channels\n",
    "        self.scale = tf.sqrt(self.gain/fan_in)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if self.pad:\n",
    "            x = tf.pad(inputs, [[0,0],[1,1],[1,1],[0,0]], mode='REFLECT')\n",
    "        else:\n",
    "            x = inputs\n",
    "        output = tf.nn.conv2d(x, self.scale*self.w, stri"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
