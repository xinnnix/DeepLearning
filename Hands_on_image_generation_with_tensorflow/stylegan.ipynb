{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec17e41-3f51-4bba-b3b2-698c9f95326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from enum import Enum\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow_addons.layers import InstanceNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ceb3931-c815-4f88-8ae7-fb0c3915d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2(x):\n",
    "    return int(np.log2(x))\n",
    "\n",
    "\n",
    "# we use different batch size for different resolution, so larger image size\n",
    "# could fit into GPU memory. The keys is image resolution in log2\n",
    "batch_sizes = {2: 16, 3: 16, 4: 16, 5: 16, 6: 16, 7: 8, 8: 4, 9: 2, 10: 1}\n",
    "# We adjust the train step accordingly\n",
    "train_step_ratio = {k: batch_sizes[2] / v for k, v in batch_sizes.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e5e8ef-5c91-451c-98a1-6ba50bdadcba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1330 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "ds_train = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"c:/Users/admin/Documents/Datasets/chinese_calligraphy/\", label_mode=None, image_size=(256, 256), batch_size=32\n",
    ")\n",
    "ds_train = ds_train.map(lambda x: x / 255.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ec2022b-0d3a-4b05-8308-2d297c114e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(res, image):\n",
    "    # only donwsampling, so use nearest neighbor that is faster to run\n",
    "    image = tf.image.resize(\n",
    "        image, (res, res), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n",
    "    )\n",
    "    image = tf.cast(image, tf.float32) / 127.5 - 1.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def create_dataloader(res):\n",
    "    batch_size = batch_sizes[log2(res)]\n",
    "    # NOTE: we unbatch the dataset so we can `batch()` it again with the `drop_remainder=True` option\n",
    "    # since the model only supports a single batch size\n",
    "    dl = ds_train.map(partial(resize_image, res), num_parallel_calls=tf.data.AUTOTUNE).unbatch()\n",
    "    dl = dl.shuffle(200).batch(batch_size, drop_remainder=True).prefetch(1).repeat()\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f2c71ac-7f53-4b42-962a-ddfaf4fd912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, log2_res, fname=\"\"):\n",
    "    scales = {2: 0.5, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7, 10: 8}\n",
    "    scale = scales[log2_res]\n",
    "\n",
    "    grid_col = min(images.shape[0], int(32 // scale))\n",
    "    grid_row = 1\n",
    "\n",
    "    f, axarr = plt.subplots(\n",
    "        grid_row, grid_col, figsize=(grid_col * scale, grid_row * scale)\n",
    "    )\n",
    "\n",
    "    for row in range(grid_row):\n",
    "        ax = axarr if grid_row == 1 else axarr[row]\n",
    "        for col in range(grid_col):\n",
    "            ax[col].imshow(images[row * grid_col + col])\n",
    "            ax[col].axis(\"off\")\n",
    "    plt.show()\n",
    "    if fname:\n",
    "        f.savefig(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa197e48-0722-4ebb-b447-9927ff6df1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fade_in(alpha, a, b):\n",
    "    return alpha * a + (1.0 - alpha) * b\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return -tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "\n",
    "def pixel_norm(x, epsilon=1e-8):\n",
    "    return x / tf.math.sqrt(tf.reduce_mean(x ** 2, axis=-1, keepdims=True) + epsilon)\n",
    "\n",
    "\n",
    "def minibatch_std(input_tensor, epsilon=1e-8):\n",
    "    n, h, w, c = tf.shape(input_tensor)\n",
    "    group_size = tf.minimum(4, n)\n",
    "    x = tf.reshape(input_tensor, [group_size, -1, h, w, c])\n",
    "    group_mean, group_var = tf.nn.moments(x, axes=(0), keepdims=False)\n",
    "    group_std = tf.sqrt(group_var + epsilon)\n",
    "    avg_std = tf.reduce_mean(group_std, axis=[1, 2, 3], keepdims=True)\n",
    "    x = tf.tile(avg_std, [group_size, h, w, 1])\n",
    "    return tf.concat([input_tensor, x], axis=-1)\n",
    "\n",
    "\n",
    "class EqualizedConv(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel=3, gain=2, **kwargs):\n",
    "        super(EqualizedConv, self).__init__(**kwargs)\n",
    "        self.kernel = kernel\n",
    "        self.out_channels = out_channels\n",
    "        self.gain = gain\n",
    "        self.pad = kernel != 1\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.in_channels = input_shape[-1]\n",
    "        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n",
    "        self.w = self.add_weight(\n",
    "            shape=[self.kernel, self.kernel, self.in_channels, self.out_channels],\n",
    "            initializer=initializer,\n",
    "            trainable=True,\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.out_channels,), initializer=\"zeros\", trainable=True, name=\"bias\"\n",
    "        )\n",
    "        fan_in = self.kernel * self.kernel * self.in_channels\n",
    "        self.scale = tf.sqrt(self.gain / fan_in)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.pad:\n",
    "            x = tf.pad(inputs, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\"REFLECT\")\n",
    "        else:\n",
    "            x = inputs\n",
    "        output = (\n",
    "            tf.nn.conv2d(x, self.scale * self.w, strides=1, padding=\"VALID\") + self.b\n",
    "        )\n",
    "        return output\n",
    "\n",
    "\n",
    "class EqualizedDense(layers.Layer):\n",
    "    def __init__(self, units, gain=2, learning_rate_multiplier=1, **kwargs):\n",
    "        super(EqualizedDense, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gain = gain\n",
    "        self.learning_rate_multiplier = learning_rate_multiplier\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.in_channels = input_shape[-1]\n",
    "        initializer = keras.initializers.RandomNormal(\n",
    "            mean=0.0, stddev=1.0 / self.learning_rate_multiplier\n",
    "        )\n",
    "        self.w = self.add_weight(\n",
    "            shape=[self.in_channels, self.units],\n",
    "            initializer=initializer,\n",
    "            trainable=True,\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"zeros\", trainable=True, name=\"bias\"\n",
    "        )\n",
    "        fan_in = self.in_channels\n",
    "        self.scale = tf.sqrt(self.gain / fan_in)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = tf.add(tf.matmul(inputs, self.scale * self.w), self.b)\n",
    "        return output * self.learning_rate_multiplier\n",
    "\n",
    "\n",
    "class AddNoise(layers.Layer):\n",
    "    def build(self, input_shape):\n",
    "        n, h, w, c = input_shape[0]\n",
    "        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n",
    "        self.b = self.add_weight(\n",
    "            shape=[1, 1, 1, c], initializer=initializer, trainable=True, name=\"kernel\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, noise = inputs\n",
    "        output = x + self.b * noise\n",
    "        return output\n",
    "\n",
    "\n",
    "class AdaIN(layers.Layer):\n",
    "    def __init__(self, gain=1, **kwargs):\n",
    "        super(AdaIN, self).__init__(**kwargs)\n",
    "        self.gain = gain\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        x_shape = input_shapes[0]\n",
    "        w_shape = input_shapes[1]\n",
    "\n",
    "        self.w_channels = w_shape[-1]\n",
    "        self.x_channels = x_shape[-1]\n",
    "\n",
    "        self.dense_1 = EqualizedDense(self.x_channels, gain=1)\n",
    "        self.dense_2 = EqualizedDense(self.x_channels, gain=1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, w = inputs\n",
    "        ys = tf.reshape(self.dense_1(w), (-1, 1, 1, self.x_channels))\n",
    "        yb = tf.reshape(self.dense_2(w), (-1, 1, 1, self.x_channels))\n",
    "        return ys * x + yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d37331-a674-4c63-b90c-4f6df00098a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mapping(num_stages, input_shape=512):\n",
    "    z = layers.Input(shape=(input_shape))\n",
    "    w = pixel_norm(z)\n",
    "    for i in range(8):\n",
    "        w = EqualizedDense(512, learning_rate_multiplier=0.01)(w)\n",
    "        w = layers.LeakyReLU(0.2)(w)\n",
    "    w = tf.tile(tf.expand_dims(w, 1), (1, num_stages, 1))\n",
    "    return keras.Model(z, w, name=\"mapping\")\n",
    "\n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, start_res_log2, target_res_log2):\n",
    "        self.start_res_log2 = start_res_log2\n",
    "        self.target_res_log2 = target_res_log2\n",
    "        self.num_stages = target_res_log2 - start_res_log2 + 1\n",
    "        # list of generator blocks at increasing resolution\n",
    "        self.g_blocks = []\n",
    "        # list of layers to convert g_block activation to RGB\n",
    "        self.to_rgb = []\n",
    "        # list of noise input of different resolutions into g_blocks\n",
    "        self.noise_inputs = []\n",
    "        # filter size to use at each stage, keys are log2(resolution)\n",
    "        self.filter_nums = {\n",
    "            0: 512,\n",
    "            1: 512,\n",
    "            2: 512,  # 4x4\n",
    "            3: 512,  # 8x8\n",
    "            4: 512,  # 16x16\n",
    "            5: 512,  # 32x32\n",
    "            6: 256,  # 64x64\n",
    "            7: 128,  # 128x128\n",
    "            8: 64,  # 256x256\n",
    "            9: 32,  # 512x512\n",
    "            10: 16,\n",
    "        }  # 1024x1024\n",
    "\n",
    "        start_res = 2 ** start_res_log2\n",
    "        self.input_shape = (start_res, start_res, self.filter_nums[start_res_log2])\n",
    "        self.g_input = layers.Input(self.input_shape, name=\"generator_input\")\n",
    "\n",
    "        for i in range(start_res_log2, target_res_log2 + 1):\n",
    "            filter_num = self.filter_nums[i]\n",
    "            res = 2 ** i\n",
    "            self.noise_inputs.append(\n",
    "                layers.Input(shape=(res, res, 1), name=f\"noise_{res}x{res}\")\n",
    "            )\n",
    "            to_rgb = Sequential(\n",
    "                [\n",
    "                    layers.InputLayer(input_shape=(res, res, filter_num)),\n",
    "                    EqualizedConv(3, 1, gain=1),\n",
    "                ],\n",
    "                name=f\"to_rgb_{res}x{res}\",\n",
    "            )\n",
    "            self.to_rgb.append(to_rgb)\n",
    "            is_base = i == self.start_res_log2\n",
    "            if is_base:\n",
    "                input_shape = (res, res, self.filter_nums[i - 1])\n",
    "            else:\n",
    "                input_shape = (2 ** (i - 1), 2 ** (i - 1), self.filter_nums[i - 1])\n",
    "            g_block = self.build_block(\n",
    "                filter_num, res=res, input_shape=input_shape, is_base=is_base\n",
    "            )\n",
    "            self.g_blocks.append(g_block)\n",
    "\n",
    "    def build_block(self, filter_num, res, input_shape, is_base):\n",
    "        input_tensor = layers.Input(shape=input_shape, name=f\"g_{res}\")\n",
    "        noise = layers.Input(shape=(res, res, 1), name=f\"noise_{res}\")\n",
    "        w = layers.Input(shape=512)\n",
    "        x = input_tensor\n",
    "\n",
    "        if not is_base:\n",
    "            x = layers.UpSampling2D((2, 2))(x)\n",
    "            x = EqualizedConv(filter_num, 3)(x)\n",
    "\n",
    "        x = AddNoise()([x, noise])\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = InstanceNormalization()(x)\n",
    "        x = AdaIN()([x, w])\n",
    "\n",
    "        x = EqualizedConv(filter_num, 3)(x)\n",
    "        x = AddNoise()([x, noise])\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = InstanceNormalization()(x)\n",
    "        x = AdaIN()([x, w])\n",
    "        return keras.Model([input_tensor, w, noise], x, name=f\"genblock_{res}x{res}\")\n",
    "\n",
    "    def grow(self, res_log2):\n",
    "        res = 2 ** res_log2\n",
    "\n",
    "        num_stages = res_log2 - self.start_res_log2 + 1\n",
    "        w = layers.Input(shape=(self.num_stages, 512), name=\"w\")\n",
    "\n",
    "        alpha = layers.Input(shape=(1), name=\"g_alpha\")\n",
    "        x = self.g_blocks[0]([self.g_input, w[:, 0], self.noise_inputs[0]])\n",
    "\n",
    "        if num_stages == 1:\n",
    "            rgb = self.to_rgb[0](x)\n",
    "        else:\n",
    "            for i in range(1, num_stages - 1):\n",
    "\n",
    "                x = self.g_blocks[i]([x, w[:, i], self.noise_inputs[i]])\n",
    "\n",
    "            old_rgb = self.to_rgb[num_stages - 2](x)\n",
    "            old_rgb = layers.UpSampling2D((2, 2))(old_rgb)\n",
    "\n",
    "            i = num_stages - 1\n",
    "            x = self.g_blocks[i]([x, w[:, i], self.noise_inputs[i]])\n",
    "\n",
    "            new_rgb = self.to_rgb[i](x)\n",
    "\n",
    "            rgb = fade_in(alpha[0], new_rgb, old_rgb)\n",
    "\n",
    "        return keras.Model(\n",
    "            [self.g_input, w, self.noise_inputs, alpha],\n",
    "            rgb,\n",
    "            name=f\"generator_{res}_x_{res}\",\n",
    "        )\n",
    "\n",
    "\n",
    "class Discriminator:\n",
    "    def __init__(self, start_res_log2, target_res_log2):\n",
    "        self.start_res_log2 = start_res_log2\n",
    "        self.target_res_log2 = target_res_log2\n",
    "        self.num_stages = target_res_log2 - start_res_log2 + 1\n",
    "        # filter size to use at each stage, keys are log2(resolution)\n",
    "        self.filter_nums = {\n",
    "            0: 512,\n",
    "            1: 512,\n",
    "            2: 512,  # 4x4\n",
    "            3: 512,  # 8x8\n",
    "            4: 512,  # 16x16\n",
    "            5: 512,  # 32x32\n",
    "            6: 256,  # 64x64\n",
    "            7: 128,  # 128x128\n",
    "            8: 64,  # 256x256\n",
    "            9: 32,  # 512x512\n",
    "            10: 16,\n",
    "        }  # 1024x1024\n",
    "        # list of discriminator blocks at increasing resolution\n",
    "        self.d_blocks = []\n",
    "        # list of layers to convert RGB into activation for d_blocks inputs\n",
    "        self.from_rgb = []\n",
    "\n",
    "        for res_log2 in range(self.start_res_log2, self.target_res_log2 + 1):\n",
    "            res = 2 ** res_log2\n",
    "            filter_num = self.filter_nums[res_log2]\n",
    "            from_rgb = Sequential(\n",
    "                [\n",
    "                    layers.InputLayer(\n",
    "                        input_shape=(res, res, 3), name=f\"from_rgb_input_{res}\"\n",
    "                    ),\n",
    "                    EqualizedConv(filter_num, 1),\n",
    "                    layers.LeakyReLU(0.2),\n",
    "                ],\n",
    "                name=f\"from_rgb_{res}\",\n",
    "            )\n",
    "\n",
    "            self.from_rgb.append(from_rgb)\n",
    "\n",
    "            input_shape = (res, res, filter_num)\n",
    "            if len(self.d_blocks) == 0:\n",
    "                d_block = self.build_base(filter_num, res)\n",
    "            else:\n",
    "                d_block = self.build_block(\n",
    "                    filter_num, self.filter_nums[res_log2 - 1], res\n",
    "                )\n",
    "\n",
    "            self.d_blocks.append(d_block)\n",
    "\n",
    "    def build_base(self, filter_num, res):\n",
    "        input_tensor = layers.Input(shape=(res, res, filter_num), name=f\"d_{res}\")\n",
    "        x = minibatch_std(input_tensor)\n",
    "        x = EqualizedConv(filter_num, 3)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = EqualizedDense(filter_num)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = EqualizedDense(1)(x)\n",
    "        return keras.Model(input_tensor, x, name=f\"d_{res}\")\n",
    "\n",
    "    def build_block(self, filter_num_1, filter_num_2, res):\n",
    "        input_tensor = layers.Input(shape=(res, res, filter_num_1), name=f\"d_{res}\")\n",
    "        x = EqualizedConv(filter_num_1, 3)(input_tensor)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = EqualizedConv(filter_num_2)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = layers.AveragePooling2D((2, 2))(x)\n",
    "        return keras.Model(input_tensor, x, name=f\"d_{res}\")\n",
    "\n",
    "    def grow(self, res_log2):\n",
    "        res = 2 ** res_log2\n",
    "        idx = res_log2 - self.start_res_log2\n",
    "        alpha = layers.Input(shape=(1), name=\"d_alpha\")\n",
    "        input_image = layers.Input(shape=(res, res, 3), name=\"input_image\")\n",
    "        x = self.from_rgb[idx](input_image)\n",
    "        x = self.d_blocks[idx](x)\n",
    "        if idx > 0:\n",
    "            idx -= 1\n",
    "            downsized_image = layers.AveragePooling2D((2, 2))(input_image)\n",
    "            y = self.from_rgb[idx](downsized_image)\n",
    "            x = fade_in(alpha[0], x, y)\n",
    "\n",
    "            for i in range(idx, -1, -1):\n",
    "                x = self.d_blocks[i](x)\n",
    "        return keras.Model([input_image, alpha], x, name=f\"discriminator_{res}_x_{res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae652d0-208a-4f7c-8fb0-edb59ac67fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleGAN(tf.keras.Model):\n",
    "    def __init__(self, z_dim=512, target_res=64, start_res=4):\n",
    "        super(StyleGAN, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.target_res_log2 = log2(target_res)\n",
    "        self.start_res_log2 = log2(start_res)\n",
    "        self.current_res_log2 = self.target_res_log2\n",
    "        self.num_stages = self.target_res_log2 - self.start_res_log2 + 1\n",
    "\n",
    "        self.alpha = tf.Variable(1.0, dtype=tf.float32, trainable=False, name=\"alpha\")\n",
    "\n",
    "        self.mapping = Mapping(num_stages=self.num_stages)\n",
    "        self.d_builder = Discriminator(self.start_res_log2, self.target_res_log2)\n",
    "        self.g_builder = Generator(self.start_res_log2, self.target_res_log2)\n",
    "        self.g_input_shape = self.g_builder.input_shape\n",
    "\n",
    "        self.phase = None\n",
    "        self.train_step_counter = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
    "\n",
    "        self.loss_weights = {\"gradient_penalty\": 10, \"drift\": 0.001}\n",
    "\n",
    "    def grow_model(self, res):\n",
    "        tf.keras.backend.clear_session()\n",
    "        res_log2 = log2(res)\n",
    "        self.generator = self.g_builder.grow(res_log2)\n",
    "        self.discriminator = self.d_builder.grow(res_log2)\n",
    "        self.current_res_log2 = res_log2\n",
    "        print(f\"\\nModel resolution:{res}x{res}\")\n",
    "\n",
    "    def compile(\n",
    "        self, steps_per_epoch, phase, res, d_optimizer, g_optimizer, *args, **kwargs\n",
    "    ):\n",
    "        self.loss_weights = kwargs.pop(\"loss_weights\", self.loss_weights)\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        if res != 2 ** self.current_res_log2:\n",
    "            self.grow_model(res)\n",
    "            self.d_optimizer = d_optimizer\n",
    "            self.g_optimizer = g_optimizer\n",
    "\n",
    "        self.train_step_counter.assign(0)\n",
    "        self.phase = phase\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "        super(StyleGAN, self).compile(*args, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def generate_noise(self, batch_size):\n",
    "        noise = [\n",
    "            tf.random.normal((batch_size, 2 ** res, 2 ** res, 1))\n",
    "            for res in range(self.start_res_log2, self.target_res_log2 + 1)\n",
    "        ]\n",
    "        return noise\n",
    "\n",
    "    def gradient_loss(self, grad):\n",
    "        loss = tf.square(grad)\n",
    "        loss = tf.reduce_sum(loss, axis=tf.range(1, tf.size(tf.shape(loss))))\n",
    "        loss = tf.sqrt(loss)\n",
    "        loss = tf.reduce_mean(tf.square(loss - 1))\n",
    "        return loss\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "\n",
    "        self.train_step_counter.assign_add(1)\n",
    "\n",
    "        if self.phase == \"TRANSITION\":\n",
    "            self.alpha.assign(\n",
    "                tf.cast(self.train_step_counter / self.steps_per_epoch, tf.float32)\n",
    "            )\n",
    "        elif self.phase == \"STABLE\":\n",
    "            self.alpha.assign(1.0)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        alpha = tf.expand_dims(self.alpha, 0)\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        real_labels = tf.ones(batch_size)\n",
    "        fake_labels = -tf.ones(batch_size)\n",
    "\n",
    "        z = tf.random.normal((batch_size, self.z_dim))\n",
    "        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n",
    "        noise = self.generate_noise(batch_size)\n",
    "\n",
    "        # generator\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            w = self.mapping(z)\n",
    "            fake_images = self.generator([const_input, w, noise, alpha])\n",
    "            pred_fake = self.discriminator([fake_images, alpha])\n",
    "            g_loss = wasserstein_loss(real_labels, pred_fake)\n",
    "\n",
    "            trainable_weights = (\n",
    "                self.mapping.trainable_weights + self.generator.trainable_weights\n",
    "            )\n",
    "            gradients = g_tape.gradient(g_loss, trainable_weights)\n",
    "            self.g_optimizer.apply_gradients(zip(gradients, trainable_weights))\n",
    "\n",
    "        # discriminator\n",
    "        with tf.GradientTape() as gradient_tape, tf.GradientTape() as total_tape:\n",
    "            # forward pass\n",
    "            pred_fake = self.discriminator([fake_images, alpha])\n",
    "            pred_real = self.discriminator([real_images, alpha])\n",
    "\n",
    "            epsilon = tf.random.uniform((batch_size, 1, 1, 1))\n",
    "            interpolates = epsilon * real_images + (1 - epsilon) * fake_images\n",
    "            gradient_tape.watch(interpolates)\n",
    "            pred_fake_grad = self.discriminator([interpolates, alpha])\n",
    "\n",
    "            # calculate losses\n",
    "            loss_fake = wasserstein_loss(fake_labels, pred_fake)\n",
    "            loss_real = wasserstein_loss(real_labels, pred_real)\n",
    "            loss_fake_grad = wasserstein_loss(fake_labels, pred_fake_grad)\n",
    "\n",
    "            # gradient penalty\n",
    "            gradients_fake = gradient_tape.gradient(loss_fake_grad, [interpolates])\n",
    "            gradient_penalty = self.loss_weights[\n",
    "                \"gradient_penalty\"\n",
    "            ] * self.gradient_loss(gradients_fake)\n",
    "\n",
    "            # drift loss\n",
    "            all_pred = tf.concat([pred_fake, pred_real], axis=0)\n",
    "            drift_loss = self.loss_weights[\"drift\"] * tf.reduce_mean(all_pred ** 2)\n",
    "\n",
    "            d_loss = loss_fake + loss_real + gradient_penalty + drift_loss\n",
    "\n",
    "            gradients = total_tape.gradient(\n",
    "                d_loss, self.discriminator.trainable_weights\n",
    "            )\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(gradients, self.discriminator.trainable_weights)\n",
    "            )\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n",
    "\n",
    "    def call(self, inputs: dict()):\n",
    "        style_code = inputs.get(\"style_code\", None)\n",
    "        z = inputs.get(\"z\", None)\n",
    "        noise = inputs.get(\"noise\", None)\n",
    "        batch_size = inputs.get(\"batch_size\", 1)\n",
    "        alpha = inputs.get(\"alpha\", 1.0)\n",
    "        alpha = tf.expand_dims(alpha, 0)\n",
    "        if style_code is None:\n",
    "            if z is None:\n",
    "                z = tf.random.normal((batch_size, self.z_dim))\n",
    "            style_code = self.mapping(z)\n",
    "\n",
    "        if noise is None:\n",
    "            noise = self.generate_noise(batch_size)\n",
    "\n",
    "        # self.alpha.assign(alpha)\n",
    "\n",
    "        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n",
    "        images = self.generator([const_input, style_code, noise, alpha])\n",
    "        images = np.clip((images * 0.5 + 0.5) * 255, 0, 255).astype(np.uint8)\n",
    "\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fc175b7-7c56-4be8-8d9d-d748b26546c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_RES = 4\n",
    "TARGET_RES = 256\n",
    "\n",
    "style_gan = StyleGAN(start_res=START_RES, target_res=TARGET_RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e835bf6b-823f-4b5d-9f87-bb9cd7130b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    start_res=START_RES,\n",
    "    target_res=TARGET_RES,\n",
    "    steps_per_epoch=5000,\n",
    "    display_images=True,\n",
    "):\n",
    "    opt_cfg = {\"learning_rate\": 1e-3, \"beta_1\": 0.0, \"beta_2\": 0.99, \"epsilon\": 1e-8}\n",
    "\n",
    "    val_batch_size = 16\n",
    "    val_z = tf.random.normal((val_batch_size, style_gan.z_dim))\n",
    "    val_noise = style_gan.generate_noise(val_batch_size)\n",
    "\n",
    "    start_res_log2 = int(np.log2(start_res))\n",
    "    target_res_log2 = int(np.log2(target_res))\n",
    "\n",
    "    for res_log2 in range(start_res_log2, target_res_log2 + 1):\n",
    "        res = 2 ** res_log2\n",
    "        for phase in [\"TRANSITION\", \"STABLE\"]:\n",
    "            if res == start_res and phase == \"TRANSITION\":\n",
    "                continue\n",
    "\n",
    "            train_dl = create_dataloader(res)\n",
    "\n",
    "            steps = int(train_step_ratio[res_log2] * steps_per_epoch)\n",
    "\n",
    "            style_gan.compile(\n",
    "                d_optimizer=tf.keras.optimizers.Adam(**opt_cfg),\n",
    "                g_optimizer=tf.keras.optimizers.Adam(**opt_cfg),\n",
    "                loss_weights={\"gradient_penalty\": 10, \"drift\": 0.001},\n",
    "                steps_per_epoch=steps,\n",
    "                res=res,\n",
    "                phase=phase,\n",
    "                run_eagerly=False,\n",
    "            )\n",
    "\n",
    "            prefix = f\"res_{res}x{res}_{style_gan.phase}\"\n",
    "\n",
    "            ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
    "                f\"checkpoints/stylegan_{res}x{res}.ckpt\",\n",
    "                save_weights_only=True,\n",
    "                verbose=0,\n",
    "            )\n",
    "            print(phase)\n",
    "            style_gan.fit(\n",
    "                train_dl, epochs=1, steps_per_epoch=steps, callbacks=[ckpt_cb]\n",
    "            )\n",
    "\n",
    "            if display_images:\n",
    "                images = style_gan({\"z\": val_z, \"noise\": val_noise, \"alpha\": 1.0})\n",
    "                plot_images(images, res_log2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01053694-e09b-4e6f-9918-d30f877abe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model resolution:4x4\n",
      "STABLE\n",
      "  766/20000 [>.............................] - ETA: 13:42 - d_loss: -11.0446 - g_loss: 11.2670"
     ]
    }
   ],
   "source": [
    "train(start_res=4, target_res=256, steps_per_epoch=20000, display_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589b0fef-9106-4847-ba4b-a5c984e871e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_gan.grow_model(256)\n",
    "# style_gan.load_weights(os.path.join(\"pretrained/stylegan_128x128.ckpt\"))\n",
    "style_gan.load_weights('./checkpoints/stylegan_256x256.ckpt')\n",
    "\n",
    "tf.random.set_seed(196)\n",
    "batch_size = 2\n",
    "z = tf.random.normal((batch_size, style_gan.z_dim))\n",
    "w = style_gan.mapping(z)\n",
    "noise = style_gan.generate_noise(batch_size=batch_size)\n",
    "images = style_gan({\"style_code\": w, \"noise\": noise, \"alpha\": 1.0})\n",
    "plot_images(images, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2723dbf8-1df2-4ca3-af58-db816146f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.4\n",
    "w_mix = np.expand_dims(alpha * w[0] + (1 - alpha) * w[1], 0)\n",
    "noise_a = [np.expand_dims(n[0], 0) for n in noise]\n",
    "mix_images = style_gan({\"style_code\": w_mix, \"noise\": noise_a})\n",
    "image_row = np.hstack([images[0], images[1], mix_images[0]])\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.imshow(image_row)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e317d57a-2a8d-4e2c-aeee-c0f7437b626f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
